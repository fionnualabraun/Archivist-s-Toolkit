For our purposes, the wget tutorial is the most useful (I thought this as well). Wget is much easier to install and use on a mac (yay!).

Looking at Chronicling America -- how can we grab all these things without having to click through all the individual newspaper pages? I tried this with the Archives of Sexuality and Gender while we were in class.
	Interesting side note, whenever you have a question mark in a URL, anything after that question mark is your query, so my query for AIDS + women on ASG looks like this: https://go-gale-com.cyber.usask.ca/ps/basicSearch.do?inputFieldNames%5B0%5D=OQE&limiterFieldValues%5BDB%5D=allElectronicResources&_limiterFieldValues%5BDB%5D=1&limiterTypes%5BDB%5D=OR&inputFieldValues%5B0%5D=AIDS+women&nwf=y&searchType=BasicSearchForm&userGroupName=usaskmain&prodId=AHSI&spellCheck=true&method=doSearch&dblist=&stw.option=&ebook=&typedCharacters=AIDS+women&listPosition=&searchMethod=submit+search&limiterTypes%5BDG%5D=OR&limiterFieldValues%5BDG%5D=&dateLimiterValues%5BDA%5D.dateMode=0&dateIndices=DA&dateLimiterValues%5BDA%5D.fromYear=&dateLimiterValues%5BDA%5D.fromMonth=&dateLimiterValues%5BDA%5D.fromDay=&dateLimiterValues%5BDA%5D.fromEra=&dateLimiterValues%5BDA%5D.toYear=&dateLimiterValues%5BDA%5D.toMonth=&dateLimiterValues%5BDA%5D.toDay=&dateLimiterValues%5BDA%5D.toEra=&standAloneLimiters=DA&singleDateLimiterValue%28DA%29.dateMode=1
	And from this you can see what the limiters and queries were that were run.
For things that are generated dynamically when you use a search, wget isn't as useful because it's not just links, it's been generated from your search! So for this, it's more useful to use the Colab notebook you tried this week.
If you need to access an archive that has some sort of key, then you would need to actually reach out to the site developers and get a key, which you would incorporate into the URL. So, this makes it a bit more difficult. So, mainly, this is useful for open-access stuff.
	Because of this, I actually got an error when I ran ASG through this, but it ran most of the way before giving me an error telling me that the API wasn't giving back something that JSON could read. It was interesting that the code I updated (attached below) actually worked all the way through to the point where the API wouldn't give me what I wanted, assuming because it wasn't open access.
	The stuff I did here is on a github repository just because I was messing around with it: https://github.com/fionnualabraun/API_Scraping_Private_Archives

### Jan.ai
Can write you code (I think) similar to Gemini on Google Colab, and you can ask it to do certain things like getting it to download images from a website all in one place. Useful as a cog in the wider process, if you already know what you want to do!

