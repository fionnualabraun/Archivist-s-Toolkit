See [[Week 7 Transcribing Handwritten Text with Python and Microsoft Azure Computer Vision]] for the tutorial notes for this week!
### Nockels et al.
HTR (Handwritten text recognition) focuses on reading text with no recognizable font, incredibly useful for things that were handwritten (obviously). Hold a lot of potential particularly for quantitative analysis of large batches of material, but I can see how they could be used to speed along the usual process of photographing, transcribing, understanding large numbers of documents for individual analysis as well.
- Mentions Transkribus, I've used this and the last time I checked it didn't work very well, or it wasn't any better than Microsoft basic OCR. Is it better now?
Mass digitization makes these tools incredibly timely, but I think we have to be careful with how we use (and endorse) mass digitization without understanding the fundamental changes and additions digitization makes to a historical document. Not to be a stodgy old person, but I don't necessarily always think that digitizing can completely replace or replicate working with an original source, both for reasons like what we saw when we were working with PDFs, and the experiential portion of it.
HTR has the potential to disrupt and expand the status quo of who is seen and heard in the archives, but only if archives also disrupt their own collecting processes in order to include documents that might become more relevant or easily accessible with HTR investigation.
- Also struggles with corpora, if everything is searchable, what are we losing out on?
HTR can encourage us to be more open with our data? Because we need to train these models and then share them in order to make them better? Something to think about...
Issues with environmental impact in that HTR is computationally taxing and harms the environment (constantly in this battle already with AI software, how do we make this better? Is there such a thing as a green computer? How do we make that? Computer science geniuses need to get on this...)
**Can be used to support research rather than replace certain elements of it. Similar to how I think we should be using LLMs, HTC is incredibly valuable but I think we should be using it to do the grunt work, not the thinking work. Isn't the whole point of computers to make life easier so we can spend more time thinking creatively?**
	Side note: I liked how transparent the authors of this article were in making their sources accessible re. Zotero database. Authors suck at this. Yay transparency!
#### HTR does this...
- Builds accurate datasets that result in less search and general transcription errors that can seriously impact data, including further digital history efforts
- Cleans existing datasets and makes them more searchable after errors were made in OCR
- Accesses a greater range of languages/personal effects in material
- Feeds back in to better training of future models every time you train it
- Accesses endangered or no longer in use languages (but is this only relevant if you know how to speak the language? Think about your ongoing battle with Anglo-Norman -- would a transcription really have helped you understand this document better?)
- Can access more voices in documents written in different hands, allows you to understand those differences better
